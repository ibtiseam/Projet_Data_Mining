{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f421bcb6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h1> <span style=\"color:red\">Classify Song Genres from Audio Data </span> </h1></center>\n",
    "\n",
    "## Réaliser par : \n",
    " <ul>\n",
    "<li><i> Ibtissem BOUZIDI 3 DNI 2</i> </li>\n",
    "<li> <i> Sabrine HOIYA 3 DNI 2 </i> </li>\n",
    "    </ul>\n",
    "    <center><img src=\"https://s3.amazonaws.com/assets.datacamp.com/production/project_449/img/iphone_music.jpg\" alt=\"Project Image Record\" width=\"200px\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616645e3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h1> <span style=\"color:red\">Problématique</span> </h1></center>\n",
    "<center><img src=\"idee.png\"  width=\"1000px\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fce69bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h1> <span style=\"color:red\">Solution</span> </h1></center>\n",
    "<center><img src=\"intro.png\"  width=\"1000px\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8532a246",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**<div class=\"alert alert-success\"> <span style=\"color:#8A2BE2\">Objectif du projet </span> </div>**\n",
    "\n",
    "* Parcourir un ensemble de données compilées par un groupe de recherche connu sous le nom de The Echo Nest.  \n",
    "* Nettoyer nos données.\n",
    "* Effectuer une visualisation exploratoire des données\n",
    "* Appliquer des algorithmes d'apprentissage automatique, tels que les <span style=\"color:#8A2BE2\">arbres de décision  </span>et la <span style=\"color:#8A2BE2\">régression logistique </span> pour de classer les chansons en tant que <i> « Hip-Hop »</i> ou <i>« Rock »</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e894fab2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\"> <span style=\"color:#800000\">Partie 1 : Pré-Traitement des données</span> </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b307c0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1/ Préparer notre jeu de données:\n",
    "* Une chanson ne se limite pas à son titre, son artiste et le nombre d'écoutes. Nous avons un autre ensemble de données qui présente des caractéristiques musicales de chaque piste telles que la danse et l'acoustique sur une échelle de -1 à 1. qui sont dans des formats différents et dans notre cas nous avons travaillé avec CSV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8db066",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Commençons par créer deux pandas DataFrames à partir de ces fichiers que nous pouvons fusionner afin d'avoir des fonctionnalités et des étiquettes (souvent également appelées X et y) pour la classification ultérieure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f69b72f7",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>bit_rate</th>\n",
       "      <th>comments</th>\n",
       "      <th>composer</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>duration</th>\n",
       "      <th>favorites</th>\n",
       "      <th>genre_top</th>\n",
       "      <th>genres</th>\n",
       "      <th>...</th>\n",
       "      <th>information</th>\n",
       "      <th>interest</th>\n",
       "      <th>language_code</th>\n",
       "      <th>license</th>\n",
       "      <th>listens</th>\n",
       "      <th>lyricist</th>\n",
       "      <th>number</th>\n",
       "      <th>publisher</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135</td>\n",
       "      <td>256000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:43:26</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>837</td>\n",
       "      <td>0</td>\n",
       "      <td>Rock</td>\n",
       "      <td>[45, 58]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2484</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>1832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Father's Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136</td>\n",
       "      <td>256000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-11-26 01:43:35</td>\n",
       "      <td>2008-11-26 00:00:00</td>\n",
       "      <td>509</td>\n",
       "      <td>0</td>\n",
       "      <td>Rock</td>\n",
       "      <td>[45, 58]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1948</td>\n",
       "      <td>en</td>\n",
       "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
       "      <td>1498</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>Peel Back The Mountain Sky</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id  bit_rate  comments composer         date_created  \\\n",
       "0       135    256000         1      NaN  2008-11-26 01:43:26   \n",
       "1       136    256000         1      NaN  2008-11-26 01:43:35   \n",
       "\n",
       "         date_recorded  duration  favorites genre_top    genres  ...  \\\n",
       "0  2008-11-26 00:00:00       837          0      Rock  [45, 58]  ...   \n",
       "1  2008-11-26 00:00:00       509          0      Rock  [45, 58]  ...   \n",
       "\n",
       "  information interest  language_code  \\\n",
       "0         NaN     2484             en   \n",
       "1         NaN     1948             en   \n",
       "\n",
       "                                             license listens  lyricist number  \\\n",
       "0  Attribution-NonCommercial-ShareAlike 3.0 Inter...    1832       NaN      0   \n",
       "1  Attribution-NonCommercial-ShareAlike 3.0 Inter...    1498       NaN      0   \n",
       "\n",
       "   publisher tags                       title  \n",
       "0        NaN   []                Father's Day  \n",
       "1        NaN   []  Peel Back The Mountain Sky  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read in track metadata with genre labels\n",
    "tracks = pd.read_csv('datasets/fma-rock-vs-hiphop.csv')\n",
    "tracks.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e9f6b02f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.416675</td>\n",
       "      <td>0.675894</td>\n",
       "      <td>0.634476</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>0.177647</td>\n",
       "      <td>0.159310</td>\n",
       "      <td>165.922</td>\n",
       "      <td>0.576661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.374408</td>\n",
       "      <td>0.528643</td>\n",
       "      <td>0.817461</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>0.105880</td>\n",
       "      <td>0.461818</td>\n",
       "      <td>126.957</td>\n",
       "      <td>0.269240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.043567</td>\n",
       "      <td>0.745566</td>\n",
       "      <td>0.701470</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>0.373143</td>\n",
       "      <td>0.124595</td>\n",
       "      <td>100.260</td>\n",
       "      <td>0.621661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0.951670</td>\n",
       "      <td>0.658179</td>\n",
       "      <td>0.924525</td>\n",
       "      <td>0.965427</td>\n",
       "      <td>0.115474</td>\n",
       "      <td>0.032985</td>\n",
       "      <td>111.562</td>\n",
       "      <td>0.963590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id  acousticness  danceability    energy  instrumentalness  liveness  \\\n",
       "0         2      0.416675      0.675894  0.634476          0.010628  0.177647   \n",
       "1         3      0.374408      0.528643  0.817461          0.001851  0.105880   \n",
       "2         5      0.043567      0.745566  0.701470          0.000697  0.373143   \n",
       "3        10      0.951670      0.658179  0.924525          0.965427  0.115474   \n",
       "\n",
       "   speechiness    tempo   valence  \n",
       "0     0.159310  165.922  0.576661  \n",
       "1     0.461818  126.957  0.269240  \n",
       "2     0.124595  100.260  0.621661  \n",
       "3     0.032985  111.562  0.963590  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in track metrics with the features\n",
    "echonest_metrics = pd.read_json('datasets/echonest-metrics.json',precise_float = True)\n",
    "echonest_metrics.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dfe00093",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>genre_top</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>153</td>\n",
       "      <td>Rock</td>\n",
       "      <td>0.988306</td>\n",
       "      <td>0.255661</td>\n",
       "      <td>0.979774</td>\n",
       "      <td>0.973006</td>\n",
       "      <td>0.121342</td>\n",
       "      <td>0.051740</td>\n",
       "      <td>90.241</td>\n",
       "      <td>0.034018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>Rock</td>\n",
       "      <td>0.970135</td>\n",
       "      <td>0.352946</td>\n",
       "      <td>0.023852</td>\n",
       "      <td>0.957113</td>\n",
       "      <td>0.113261</td>\n",
       "      <td>0.032177</td>\n",
       "      <td>53.758</td>\n",
       "      <td>0.035632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id genre_top  acousticness  danceability    energy  instrumentalness  \\\n",
       "0       153      Rock      0.988306      0.255661  0.979774          0.973006   \n",
       "1       154      Rock      0.970135      0.352946  0.023852          0.957113   \n",
       "\n",
       "   liveness  speechiness   tempo   valence  \n",
       "0  0.121342     0.051740  90.241  0.034018  \n",
       "1  0.113261     0.032177  53.758  0.035632  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the track_id and genre_top columns of tracks and echonest_metrics on track_id values\n",
    "echo_tracks = pd.merge(left = tracks[['track_id', 'genre_top']], right=echonest_metrics, on='track_id')\n",
    "echo_tracks.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "80f3d27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4802 entries, 0 to 4801\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   track_id          4802 non-null   int64  \n",
      " 1   genre_top         4802 non-null   object \n",
      " 2   acousticness      4802 non-null   float64\n",
      " 3   danceability      4802 non-null   float64\n",
      " 4   energy            4802 non-null   float64\n",
      " 5   instrumentalness  4802 non-null   float64\n",
      " 6   liveness          4802 non-null   float64\n",
      " 7   speechiness       4802 non-null   float64\n",
      " 8   tempo             4802 non-null   float64\n",
      " 9   valence           4802 non-null   float64\n",
      "dtypes: float64(8), int64(1), object(1)\n",
      "memory usage: 412.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Inspect the resultant dataframe\n",
    "echo_tracks.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26978319",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2/ Relations par paires entre variables continues:\n",
    "Il faut éviter d'utiliser des variables qui ont de fortes corrélations les unes avec les autres, ainsi la redondance- pour plusieurs raisons:\n",
    "<div class=\"alert alert-success\"> <span style=\"color:#707000\">\n",
    " <ul>\n",
    "<li><i> Pour garder le modèle simple et améliorer l'interprétabilité (surapprentissage).</i> </li>\n",
    "<li> <i>Lorsque nos Datasets sont très volumineux, l'utilisation de moins de fonctionnalités peut considérablement accélérer notre temps de calcul.</i> </li>\n",
    "    </ul>\n",
    " </span></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d52459d6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_140ff_row0_col0,#T_140ff_row1_col1,#T_140ff_row2_col2,#T_140ff_row3_col3,#T_140ff_row4_col4,#T_140ff_row5_col5,#T_140ff_row6_col6,#T_140ff_row7_col7,#T_140ff_row8_col8{\n",
       "            background-color:  #023858;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_140ff_row0_col1,#T_140ff_row1_col0,#T_140ff_row1_col3,#T_140ff_row2_col5,#T_140ff_row2_col7,#T_140ff_row4_col2,#T_140ff_row4_col6,#T_140ff_row4_col8,#T_140ff_row6_col4{\n",
       "            background-color:  #fff7fb;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row0_col2{\n",
       "            background-color:  #d2d2e7;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row0_col3{\n",
       "            background-color:  #b5c4df;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row0_col4{\n",
       "            background-color:  #f5eef6;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row0_col5{\n",
       "            background-color:  #e9e5f1;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row0_col6,#T_140ff_row8_col3{\n",
       "            background-color:  #d1d2e6;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row0_col7,#T_140ff_row1_col7{\n",
       "            background-color:  #e1dfed;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row0_col8,#T_140ff_row3_col6{\n",
       "            background-color:  #dedcec;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row1_col2{\n",
       "            background-color:  #e0dded;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row1_col4,#T_140ff_row4_col1{\n",
       "            background-color:  #97b7d7;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row1_col5,#T_140ff_row2_col4{\n",
       "            background-color:  #f3edf5;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row1_col6,#T_140ff_row6_col1{\n",
       "            background-color:  #b8c6e0;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row1_col8{\n",
       "            background-color:  #e2dfee;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row2_col0,#T_140ff_row5_col0,#T_140ff_row5_col3{\n",
       "            background-color:  #bdc8e1;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row2_col1,#T_140ff_row6_col0,#T_140ff_row7_col0,#T_140ff_row7_col1{\n",
       "            background-color:  #d0d1e6;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row2_col3{\n",
       "            background-color:  #fbf3f9;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row2_col6{\n",
       "            background-color:  #80aed2;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row2_col8{\n",
       "            background-color:  #529bc7;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row3_col0,#T_140ff_row7_col3{\n",
       "            background-color:  #a7bddb;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row3_col1{\n",
       "            background-color:  #f5eff6;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row3_col2,#T_140ff_row7_col2{\n",
       "            background-color:  #fef6fa;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row3_col4{\n",
       "            background-color:  #c4cbe3;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row3_col5,#T_140ff_row5_col7{\n",
       "            background-color:  #dcdaeb;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row3_col7{\n",
       "            background-color:  #adc1dd;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row3_col8,#T_140ff_row4_col7{\n",
       "            background-color:  #d9d8ea;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row4_col0{\n",
       "            background-color:  #f4eef6;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row4_col3{\n",
       "            background-color:  #d2d3e7;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row4_col5{\n",
       "            background-color:  #fdf5fa;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row5_col1{\n",
       "            background-color:  #ced0e6;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row5_col2{\n",
       "            background-color:  #ede8f3;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row5_col4,#T_140ff_row6_col7{\n",
       "            background-color:  #dbdaeb;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row5_col6{\n",
       "            background-color:  #c0c9e2;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row5_col8{\n",
       "            background-color:  #e8e4f0;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row6_col2{\n",
       "            background-color:  #93b5d6;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row6_col3,#T_140ff_row6_col5{\n",
       "            background-color:  #eae6f1;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row6_col8{\n",
       "            background-color:  #bfc9e1;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row7_col4{\n",
       "            background-color:  #c5cce3;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row7_col5{\n",
       "            background-color:  #f0eaf4;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row7_col6{\n",
       "            background-color:  #c8cde4;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row7_col8{\n",
       "            background-color:  #d6d6e9;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row8_col0{\n",
       "            background-color:  #c6cce3;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row8_col1{\n",
       "            background-color:  #cdd0e5;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row8_col2{\n",
       "            background-color:  #4c99c5;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row8_col4{\n",
       "            background-color:  #efe9f3;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row8_col5{\n",
       "            background-color:  #f7f0f7;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row8_col6{\n",
       "            background-color:  #a5bddb;\n",
       "            color:  #000000;\n",
       "        }#T_140ff_row8_col7{\n",
       "            background-color:  #d3d4e7;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_140ff_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >track_id</th>        <th class=\"col_heading level0 col1\" >acousticness</th>        <th class=\"col_heading level0 col2\" >danceability</th>        <th class=\"col_heading level0 col3\" >energy</th>        <th class=\"col_heading level0 col4\" >instrumentalness</th>        <th class=\"col_heading level0 col5\" >liveness</th>        <th class=\"col_heading level0 col6\" >speechiness</th>        <th class=\"col_heading level0 col7\" >tempo</th>        <th class=\"col_heading level0 col8\" >valence</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_140ff_level0_row0\" class=\"row_heading level0 row0\" >track_id</th>\n",
       "                        <td id=\"T_140ff_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "                        <td id=\"T_140ff_row0_col1\" class=\"data row0 col1\" >-0.372282</td>\n",
       "                        <td id=\"T_140ff_row0_col2\" class=\"data row0 col2\" >0.049454</td>\n",
       "                        <td id=\"T_140ff_row0_col3\" class=\"data row0 col3\" >0.140703</td>\n",
       "                        <td id=\"T_140ff_row0_col4\" class=\"data row0 col4\" >-0.275623</td>\n",
       "                        <td id=\"T_140ff_row0_col5\" class=\"data row0 col5\" >0.048231</td>\n",
       "                        <td id=\"T_140ff_row0_col6\" class=\"data row0 col6\" >-0.026995</td>\n",
       "                        <td id=\"T_140ff_row0_col7\" class=\"data row0 col7\" >-0.025392</td>\n",
       "                        <td id=\"T_140ff_row0_col8\" class=\"data row0 col8\" >0.010070</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_140ff_level0_row1\" class=\"row_heading level0 row1\" >acousticness</th>\n",
       "                        <td id=\"T_140ff_row1_col0\" class=\"data row1 col0\" >-0.372282</td>\n",
       "                        <td id=\"T_140ff_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "                        <td id=\"T_140ff_row1_col2\" class=\"data row1 col2\" >-0.028954</td>\n",
       "                        <td id=\"T_140ff_row1_col3\" class=\"data row1 col3\" >-0.281619</td>\n",
       "                        <td id=\"T_140ff_row1_col4\" class=\"data row1 col4\" >0.194780</td>\n",
       "                        <td id=\"T_140ff_row1_col5\" class=\"data row1 col5\" >-0.019991</td>\n",
       "                        <td id=\"T_140ff_row1_col6\" class=\"data row1 col6\" >0.072204</td>\n",
       "                        <td id=\"T_140ff_row1_col7\" class=\"data row1 col7\" >-0.026310</td>\n",
       "                        <td id=\"T_140ff_row1_col8\" class=\"data row1 col8\" >-0.013841</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_140ff_level0_row2\" class=\"row_heading level0 row2\" >danceability</th>\n",
       "                        <td id=\"T_140ff_row2_col0\" class=\"data row2 col0\" >0.049454</td>\n",
       "                        <td id=\"T_140ff_row2_col1\" class=\"data row2 col1\" >-0.028954</td>\n",
       "                        <td id=\"T_140ff_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "                        <td id=\"T_140ff_row2_col3\" class=\"data row2 col3\" >-0.242032</td>\n",
       "                        <td id=\"T_140ff_row2_col4\" class=\"data row2 col4\" >-0.255217</td>\n",
       "                        <td id=\"T_140ff_row2_col5\" class=\"data row2 col5\" >-0.106584</td>\n",
       "                        <td id=\"T_140ff_row2_col6\" class=\"data row2 col6\" >0.276206</td>\n",
       "                        <td id=\"T_140ff_row2_col7\" class=\"data row2 col7\" >-0.242089</td>\n",
       "                        <td id=\"T_140ff_row2_col8\" class=\"data row2 col8\" >0.473165</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_140ff_level0_row3\" class=\"row_heading level0 row3\" >energy</th>\n",
       "                        <td id=\"T_140ff_row3_col0\" class=\"data row3 col0\" >0.140703</td>\n",
       "                        <td id=\"T_140ff_row3_col1\" class=\"data row3 col1\" >-0.281619</td>\n",
       "                        <td id=\"T_140ff_row3_col2\" class=\"data row3 col2\" >-0.242032</td>\n",
       "                        <td id=\"T_140ff_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "                        <td id=\"T_140ff_row3_col4\" class=\"data row3 col4\" >0.028238</td>\n",
       "                        <td id=\"T_140ff_row3_col5\" class=\"data row3 col5\" >0.113331</td>\n",
       "                        <td id=\"T_140ff_row3_col6\" class=\"data row3 col6\" >-0.109983</td>\n",
       "                        <td id=\"T_140ff_row3_col7\" class=\"data row3 col7\" >0.195227</td>\n",
       "                        <td id=\"T_140ff_row3_col8\" class=\"data row3 col8\" >0.038603</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_140ff_level0_row4\" class=\"row_heading level0 row4\" >instrumentalness</th>\n",
       "                        <td id=\"T_140ff_row4_col0\" class=\"data row4 col0\" >-0.275623</td>\n",
       "                        <td id=\"T_140ff_row4_col1\" class=\"data row4 col1\" >0.194780</td>\n",
       "                        <td id=\"T_140ff_row4_col2\" class=\"data row4 col2\" >-0.255217</td>\n",
       "                        <td id=\"T_140ff_row4_col3\" class=\"data row4 col3\" >0.028238</td>\n",
       "                        <td id=\"T_140ff_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "                        <td id=\"T_140ff_row4_col5\" class=\"data row4 col5\" >-0.091022</td>\n",
       "                        <td id=\"T_140ff_row4_col6\" class=\"data row4 col6\" >-0.366762</td>\n",
       "                        <td id=\"T_140ff_row4_col7\" class=\"data row4 col7\" >0.022215</td>\n",
       "                        <td id=\"T_140ff_row4_col8\" class=\"data row4 col8\" >-0.219967</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_140ff_level0_row5\" class=\"row_heading level0 row5\" >liveness</th>\n",
       "                        <td id=\"T_140ff_row5_col0\" class=\"data row5 col0\" >0.048231</td>\n",
       "                        <td id=\"T_140ff_row5_col1\" class=\"data row5 col1\" >-0.019991</td>\n",
       "                        <td id=\"T_140ff_row5_col2\" class=\"data row5 col2\" >-0.106584</td>\n",
       "                        <td id=\"T_140ff_row5_col3\" class=\"data row5 col3\" >0.113331</td>\n",
       "                        <td id=\"T_140ff_row5_col4\" class=\"data row5 col4\" >-0.091022</td>\n",
       "                        <td id=\"T_140ff_row5_col5\" class=\"data row5 col5\" >1.000000</td>\n",
       "                        <td id=\"T_140ff_row5_col6\" class=\"data row5 col6\" >0.041173</td>\n",
       "                        <td id=\"T_140ff_row5_col7\" class=\"data row5 col7\" >0.002732</td>\n",
       "                        <td id=\"T_140ff_row5_col8\" class=\"data row5 col8\" >-0.045093</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_140ff_level0_row6\" class=\"row_heading level0 row6\" >speechiness</th>\n",
       "                        <td id=\"T_140ff_row6_col0\" class=\"data row6 col0\" >-0.026995</td>\n",
       "                        <td id=\"T_140ff_row6_col1\" class=\"data row6 col1\" >0.072204</td>\n",
       "                        <td id=\"T_140ff_row6_col2\" class=\"data row6 col2\" >0.276206</td>\n",
       "                        <td id=\"T_140ff_row6_col3\" class=\"data row6 col3\" >-0.109983</td>\n",
       "                        <td id=\"T_140ff_row6_col4\" class=\"data row6 col4\" >-0.366762</td>\n",
       "                        <td id=\"T_140ff_row6_col5\" class=\"data row6 col5\" >0.041173</td>\n",
       "                        <td id=\"T_140ff_row6_col6\" class=\"data row6 col6\" >1.000000</td>\n",
       "                        <td id=\"T_140ff_row6_col7\" class=\"data row6 col7\" >0.008241</td>\n",
       "                        <td id=\"T_140ff_row6_col8\" class=\"data row6 col8\" >0.149894</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_140ff_level0_row7\" class=\"row_heading level0 row7\" >tempo</th>\n",
       "                        <td id=\"T_140ff_row7_col0\" class=\"data row7 col0\" >-0.025392</td>\n",
       "                        <td id=\"T_140ff_row7_col1\" class=\"data row7 col1\" >-0.026310</td>\n",
       "                        <td id=\"T_140ff_row7_col2\" class=\"data row7 col2\" >-0.242089</td>\n",
       "                        <td id=\"T_140ff_row7_col3\" class=\"data row7 col3\" >0.195227</td>\n",
       "                        <td id=\"T_140ff_row7_col4\" class=\"data row7 col4\" >0.022215</td>\n",
       "                        <td id=\"T_140ff_row7_col5\" class=\"data row7 col5\" >0.002732</td>\n",
       "                        <td id=\"T_140ff_row7_col6\" class=\"data row7 col6\" >0.008241</td>\n",
       "                        <td id=\"T_140ff_row7_col7\" class=\"data row7 col7\" >1.000000</td>\n",
       "                        <td id=\"T_140ff_row7_col8\" class=\"data row7 col8\" >0.052221</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_140ff_level0_row8\" class=\"row_heading level0 row8\" >valence</th>\n",
       "                        <td id=\"T_140ff_row8_col0\" class=\"data row8 col0\" >0.010070</td>\n",
       "                        <td id=\"T_140ff_row8_col1\" class=\"data row8 col1\" >-0.013841</td>\n",
       "                        <td id=\"T_140ff_row8_col2\" class=\"data row8 col2\" >0.473165</td>\n",
       "                        <td id=\"T_140ff_row8_col3\" class=\"data row8 col3\" >0.038603</td>\n",
       "                        <td id=\"T_140ff_row8_col4\" class=\"data row8 col4\" >-0.219967</td>\n",
       "                        <td id=\"T_140ff_row8_col5\" class=\"data row8 col5\" >-0.045093</td>\n",
       "                        <td id=\"T_140ff_row8_col6\" class=\"data row8 col6\" >0.149894</td>\n",
       "                        <td id=\"T_140ff_row8_col7\" class=\"data row8 col7\" >0.052221</td>\n",
       "                        <td id=\"T_140ff_row8_col8\" class=\"data row8 col8\" >1.000000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2b03d0fef40>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a correlation matrix\n",
    "corr_metrics = echo_tracks.corr()\n",
    "corr_metrics.style.background_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ee18d0",
   "metadata": {},
   "source": [
    "<span style=\"color:orange\"><b>Ici, nous pouvons voir une corrélation intéressante entre danceability et valence, mais elle n'est pas assez forte.</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b5bdbe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3/ Normaliser les données\n",
    "&#9888; &#x26A0; Simplifier nos modèles et les fonctionnalités nécessaire pour obtenir le meilleur résultat.<br>\n",
    "&#x2611; Utiliser une approche pour réduire le nombre de caractéristiques appelée Analyse en Composantes Principales (ACP) est une méthode de <code>dimensionality reduction</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dea9352",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* <span style=\"color:red\"><b>Probleme:</b></span><br>\n",
    "<i>PCA utilise la variance absolue d'une caractéristique pour faire pivoter les données, une caractéristique avec une plage de valeurs plus large dominera et biaisera l'algorithme par rapport aux autres caractéristiques</i> <br>\n",
    "* <span style=\"color:#0000C0\"><b>Solution:</b></span><br>\n",
    "<i>Il existe plusieurs méthodes, mais une méthode courante consiste à utiliser la standardisation , de sorte que toutes les caractéristiques aient une moyenne = 0 et un écart type = 1. </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "034e5454",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.36170559, -0.98589622,  1.45332318, ..., -0.36415677,\n",
       "        -1.07200261, -1.57310227],\n",
       "       [ 1.31234237, -0.45568108, -2.46398518, ..., -0.49822414,\n",
       "        -2.14506572, -1.5670495 ],\n",
       "       [ 1.34364478, -1.60400213,  1.17609079, ..., -0.11890299,\n",
       "        -1.022854  , -1.57194929],\n",
       "       ...,\n",
       "       [-1.29470431,  1.17682795,  0.13265633, ...,  0.85182206,\n",
       "        -0.93541008, -0.07941825],\n",
       "       [-1.13869115, -0.02253433,  0.57117905, ...,  1.40951543,\n",
       "         1.31301348,  0.47513794],\n",
       "       [-0.90611434,  1.10148973,  0.56322452, ...,  1.36030881,\n",
       "        -1.43669053,  0.76217464]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define our features \n",
    "features = echo_tracks.drop(['genre_top', 'track_id'], axis = 1)\n",
    "# Define our labels\n",
    "labels = echo_tracks['genre_top']\n",
    "# Import the StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Scale the features and set the values to a new variable\n",
    "scaler = StandardScaler()\n",
    "scaled_train_features = scaler.fit_transform(features)\n",
    "scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d044f6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4/ Analyse en Composantes Principales sur nos données à l'échelle: \n",
    "Nous avons prétraité nos données, nous sommes prêts à utiliser la PCA pour déterminer de combien nous pouvons réduire la dimensionnalité de nos données. On utilise <strong>scree-plots</strong> et <strong>cumulative explained ratio plots</strong> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6239e46",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Les <strong>scree-plots</strong> affichent le nombre de composants par rapport à la variance expliquée par chaque composant, triés par ordre décroissant de variance. \n",
    "* Les scree-plots nous aident à mieux comprendre quels composants expliquent une quantité suffisante de variance dans nos données. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0bb95c04",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "# Obtenez nos rapport de variance expliqués de PCA en utilisant toutes les features\n",
    "pca = PCA()\n",
    "pca.fit(scaled_train_features)\n",
    "exp_variance = pca.explained_variance_ratio_\n",
    "#exp_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8d974272",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the explained variance using a barplot\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(range(pca.n_components_),exp_variance)\n",
    "ax.set_xlabel('Principal Component #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02760a91",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5/ Visualisation plus poussée de l'ACP:\n",
    "<p>😣 Malheureusement, il ne semble pas y avoir de coude clair dans ce tracé, ce qui signifie qu'il n'est pas simple de trouver le nombre de dimensions intrinsèques à l'aide de cette méthode. Au lieu de cela, nous pouvons examiner le graphique de la variance expliquée cumulative pour déterminer combien de caractéristiques sont nécessairesdisons, environ 90 % de la variance.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ca0aaab6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24297674, 0.4234199 , 0.55992299, 0.68986388, 0.80042636,\n",
       "       0.88344881, 0.95268664, 1.        ])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the cumulative explained variance\n",
    "cum_exp_variance = np.cumsum(exp_variance)\n",
    "cum_exp_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a987b6e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-a66335fcaf4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Plot the cumulative explained variance and draw a dashed line at 0.90.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcum_exp_variance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxhline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'--'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'y'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the cumulative explained variance and draw a dashed line at 0.90.\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(8),cum_exp_variance).y\n",
    " \n",
    "ax.axhline(y=0.9, linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8a3fe48a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# choose the n_components where about 85% of our variance can be explained\n",
    "n_components = 7\n",
    "\n",
    "# Perform PCA with the chosen number of components and project data onto components\n",
    "pca = PCA(n_components, random_state=10)\n",
    "pca.fit(scaled_train_features)\n",
    "pca_projection = pca.transform(scaled_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cfc44fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4802, 8)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c0a691a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4802, 7)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_projection.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e339c3b8",
   "metadata": {},
   "source": [
    "> Nous pouvons maintenant utiliser PCA de dimension inférieure des données pour classer les chansons en genres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf55736",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6/ Arbre de décision:\n",
    "\n",
    "> Un arbre de décision est un outil d'aide à la décision représentant un ensemble de choix sous la forme graphique d'un arbre. Les différentes décisions possibles sont situées aux extrémités des branches, et sont atteintes en fonction de décisions prises à chaque étape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32bd84c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"https://s3.amazonaws.com/assets.datacamp.com/production/project_449/img/simple_decision_tree.png\" alt=\"Decision Tree Flow Chart Example\" width=\"350px\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dabdbae",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* <span style=\"color:red\"><b>Etape 1:</b></span> Diviser notre ensemble de données en sous-ensembles « train » et « test »."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "50e7aa8c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=10)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import train_test_split function and Decision tree classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split our data\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(pca_projection, labels, stratify = labels)\n",
    "\n",
    "# Train our decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(random_state = 10)\n",
    "tree.fit(train_features, train_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1ff1c8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* <span style=\"color:red\"><b>Etape 2:</b></span> Prédiction des données à partir de l'arbre entraîner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e0d70e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for the test data\n",
    "pred_labels_tree = tree.predict(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9259bc07",
   "metadata": {},
   "source": [
    "* Score de classification de précision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "758a6d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8726061615320566"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_labels, pred_labels_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7919b8",
   "metadata": {},
   "source": [
    "<span style=\"color:orange\"><b>L'ensemble d'étiquettes prédit pour un échantillon correspondre 80% à l'ensemble d'étiquettes correspondant dans test_labels.</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc88b2df",
   "metadata": {},
   "source": [
    "* Mais pourquoi il ne sont pas exact 🤔🤔??? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8d2bd837",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rock       3892\n",
       "Hip-Hop     910\n",
       "Name: genre_top, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bfb453",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "> Nos données sont déséquilibrées, donc ici la précision n'est pas vraiment une bonne mesure. Regardons la matrice de confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a636e2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[134,  94],\n",
       "       [ 59, 914]], dtype=int64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_labels, pred_labels_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb094a8",
   "metadata": {},
   "source": [
    "> Il faut tester au moins quelques autres algorithmes et de trouver qui convient le mieux à nos données, et qui seront encore plus performants "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d085fc2a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 7/ Arbre de décision vs Régression logistique\n",
    "Parfois, le plus simple est le meilleur, et nous allons donc commencer par appliquer la régression logistique . La régression logistique utilise ce qu'on appelle la fonction logistique pour calculer les chances qu'un point de données donné appartienne à une classe donnée.</br>\n",
    "\n",
    "<center><img src=\"https://datascientest.com/wp-content/uploads/2020/11/illu_regression_blog-16-1024x562.png\" alt=\"Decision Tree Flow Chart Example\" width=\"350px\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6e9e37",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Une fois que nous avons les deux modèles, nous pouvons les comparer sur quelques mesures de performance, telles que le taux de faux positifs et de faux négatifs (ou combien de points sont classés de manière inexacte)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d376176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train our logistic regression and predict labels for the test set\n",
    "logreg = LogisticRegression(random_state = 10)\n",
    "logreg.fit(train_features, train_labels)\n",
    "pred_labels_logit = logreg.predict(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dc3717",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Créer le rapport de classification pour les deux modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f31738e0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Hip-Hop       0.69      0.59      0.64       228\n",
      "        Rock       0.91      0.94      0.92       973\n",
      "\n",
      "    accuracy                           0.87      1201\n",
      "   macro avg       0.80      0.76      0.78      1201\n",
      "weighted avg       0.87      0.87      0.87      1201\n",
      "\n",
      "Logistic Regression: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Hip-Hop       0.85      0.51      0.64       228\n",
      "        Rock       0.89      0.98      0.93       973\n",
      "\n",
      "    accuracy                           0.89      1201\n",
      "   macro avg       0.87      0.74      0.79      1201\n",
      "weighted avg       0.89      0.89      0.88      1201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "class_rep_tree = classification_report(test_labels, pred_labels_tree)\n",
    "class_rep_log = classification_report(test_labels, pred_labels_logit)\n",
    "\n",
    "print(\"Decision Tree: \\n\", class_rep_tree)\n",
    "print(\"Logistic Regression: \\n\", class_rep_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f9329f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8/ Équilibrer nos données pour plus de performances :\n",
    "Nos deux modèles fonctionnent de manière similaire, avec une précision moyenne de 87 % chacun.\n",
    "En regardant notre rapport de classification, nous pouvons voir que les chansons rock sont assez bien classées, mais les chansons hip-hop sont classées à de manière disproportionnée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "50956d33",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>genre_top</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>153</td>\n",
       "      <td>Rock</td>\n",
       "      <td>0.988306</td>\n",
       "      <td>0.255661</td>\n",
       "      <td>0.979774</td>\n",
       "      <td>0.973006</td>\n",
       "      <td>0.121342</td>\n",
       "      <td>0.051740</td>\n",
       "      <td>90.241</td>\n",
       "      <td>0.034018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>Rock</td>\n",
       "      <td>0.970135</td>\n",
       "      <td>0.352946</td>\n",
       "      <td>0.023852</td>\n",
       "      <td>0.957113</td>\n",
       "      <td>0.113261</td>\n",
       "      <td>0.032177</td>\n",
       "      <td>53.758</td>\n",
       "      <td>0.035632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>155</td>\n",
       "      <td>Rock</td>\n",
       "      <td>0.981657</td>\n",
       "      <td>0.142249</td>\n",
       "      <td>0.912122</td>\n",
       "      <td>0.967294</td>\n",
       "      <td>0.363510</td>\n",
       "      <td>0.087527</td>\n",
       "      <td>91.912</td>\n",
       "      <td>0.034325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>169</td>\n",
       "      <td>Rock</td>\n",
       "      <td>0.989141</td>\n",
       "      <td>0.225978</td>\n",
       "      <td>0.722835</td>\n",
       "      <td>0.263076</td>\n",
       "      <td>0.092371</td>\n",
       "      <td>0.053406</td>\n",
       "      <td>94.322</td>\n",
       "      <td>0.028347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170</td>\n",
       "      <td>Rock</td>\n",
       "      <td>0.886660</td>\n",
       "      <td>0.298518</td>\n",
       "      <td>0.744333</td>\n",
       "      <td>0.920950</td>\n",
       "      <td>0.139587</td>\n",
       "      <td>0.088781</td>\n",
       "      <td>97.880</td>\n",
       "      <td>0.073548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id genre_top  acousticness  danceability    energy  instrumentalness  \\\n",
       "0       153      Rock      0.988306      0.255661  0.979774          0.973006   \n",
       "1       154      Rock      0.970135      0.352946  0.023852          0.957113   \n",
       "2       155      Rock      0.981657      0.142249  0.912122          0.967294   \n",
       "3       169      Rock      0.989141      0.225978  0.722835          0.263076   \n",
       "4       170      Rock      0.886660      0.298518  0.744333          0.920950   \n",
       "\n",
       "   liveness  speechiness   tempo   valence  \n",
       "0  0.121342     0.051740  90.241  0.034018  \n",
       "1  0.113261     0.032177  53.758  0.035632  \n",
       "2  0.363510     0.087527  91.912  0.034325  \n",
       "3  0.092371     0.053406  94.322  0.028347  \n",
       "4  0.139587     0.088781  97.880  0.073548  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset only the hip-hop tracks, and then only the rock tracks\n",
    "hop_only = echo_tracks.loc[echo_tracks['genre_top'] == 'Hip-Hop']\n",
    "rock_only = echo_tracks.loc[echo_tracks['genre_top'] == 'Rock']\n",
    "rock_only.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5d128841",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3892, 10), (910, 10))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock_only.shape, hop_only.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f5edac",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Echantillonnez les chansons rock pour qu'elles soient le même nombre qu'il y a des chansons hip-hop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7064259b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((910, 10), (910, 10))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rock_only = rock_only.sample(n= hop_only.shape[0])\n",
    "rock_only.shape, hop_only.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "93ac304a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1820, 10)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate the dataframes rock_only and hop_only\n",
    "rock_hop_bal = pd.concat([rock_only, hop_only])\n",
    "rock_hop_bal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ed55a8c4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# The features, labels, and pca projection are created for the balanced dataframe\n",
    "features = rock_hop_bal.drop(['genre_top', 'track_id'], axis=1) \n",
    "labels = rock_hop_bal['genre_top']\n",
    "pca_projection = pca.fit_transform(scaler.fit_transform(features))\n",
    "\n",
    "# Redefine the train and test set with the pca_projection from the balanced data\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(pca_projection,\n",
    "                                                                            labels,\n",
    "                                                                            stratify = labels,\n",
    "                                                                            random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef31d1f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  L'équilibrage de notre ensemble de données améliore-t-il le biais du modèle ?\n",
    "Nous avons maintenant équilibré notre ensemble de données, mais nous avons supprimé de nombreux points de données qui auraient pu être cruciaux pour l'entraînement de nos modèles. \n",
    "* Testons pour voir si l'équilibrage de nos données améliore le biais du modèle vers la classification « Rock » tout en conservant les performances globales de la classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "639b3462",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Train our decision tree on the balanced data\n",
    "tree = DecisionTreeClassifier(random_state=10)\n",
    "tree.fit(train_features, train_labels)\n",
    "pred_labels_tree = tree.predict(test_features)\n",
    "\n",
    "# Train our logistic regression on the balanced data\n",
    "logreg = LogisticRegression(random_state = 10)\n",
    "logreg.fit(train_features, train_labels)\n",
    "pred_labels_logit = logreg.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e13eec5b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Hip-Hop       0.79      0.78      0.78       227\n",
      "        Rock       0.78      0.79      0.79       228\n",
      "\n",
      "    accuracy                           0.78       455\n",
      "   macro avg       0.78      0.78      0.78       455\n",
      "weighted avg       0.78      0.78      0.78       455\n",
      "\n",
      "Logistic Regression: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Hip-Hop       0.87      0.79      0.83       227\n",
      "        Rock       0.81      0.89      0.85       228\n",
      "\n",
      "    accuracy                           0.84       455\n",
      "   macro avg       0.84      0.84      0.84       455\n",
      "weighted avg       0.84      0.84      0.84       455\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare the models\n",
    "print(\"Decision Tree: \\n\", classification_report(test_labels, pred_labels_tree))\n",
    "print(\"Logistic Regression: \\n\", classification_report(test_labels, pred_labels_logit))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aedbd1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h1> <span style=\"color:red\"> validation croisée pour évaluer nos modèles</span> </h1></center>\n",
    "Succès! L'équilibrage de nos données a supprimé le biais en faveur de la classe la plus répandue. Pour avoir une bonne idée de la performance réelle de nos modèles, nous pouvons appliquer ce qu'on appelle la validation croisée (CV). Cette étape nous permet de comparer les modèles de façon plus rigoureuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "da36f01c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: 0.810989010989011 Logistic Regression: 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# Set up our K-fold cross-validation\n",
    "kf = KFold(n_splits=10, random_state=10, shuffle=True)\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=10)\n",
    "logreg = LogisticRegression(random_state=10)\n",
    "\n",
    "# Train our models using KFold cv\n",
    "tree_score = cross_val_score(tree, pca_projection, labels, cv = kf)\n",
    "logit_score = cross_val_score(logreg, pca_projection, labels, cv = kf)\n",
    "\n",
    "# Print the mean of each array of scores\n",
    "print(\"Decision Tree:\", np.mean(tree_score),\n",
    "      \"Logistic Regression:\", np.mean(logit_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601a7a20",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\"> <span style=\"color:#800000\">\n",
    "Nous pouvons voir ici que notre modèle de régression logistique simple a donné de meilleurs résultats que le modèle d'arbre de décision sur les données équilibrées. Nous pouvons essayer des modèles plus avancés comme Random Forest et SVM pour améliorer nos résultats.</span> </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c1d82b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
